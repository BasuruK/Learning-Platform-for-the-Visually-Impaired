{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# This model trains a CNN using Sequential model in Keras.\\n# The CNN is a Deep CNN with 2 Convolutional Layers followed by a Artificial Neural Network with 2 hiden layers of\\n# 128 and 256 nodes in each with ReLU activation function followed by an Softmax output layer\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# This model trains a CNN using Sequential model in Keras.\n",
    "# The CNN is a Deep CNN with 2 Convolutional Layers followed by a Artificial Neural Network with 2 hiden layers of\n",
    "# 128 and 256 nodes in each with ReLU activation function followed by an Softmax output layer\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Keras and Tensorflow modules\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image as img\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "np.random.seed(7)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initilize the CNN\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1 - Convolution\n",
    "\n",
    "classifier.add(Conv2D(32, (5, 5), input_shape = (64, 64, 3), activation = 'relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 2 - Add more Convolution Layers making it Deep followed by a Pooling Layer\n",
    "\n",
    "classifier.add(Conv2D(32, (5, 5), activation = 'relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Conv2D(64, (5, 5), activation = 'relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(128, (5, 5), activation = 'relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4 - Fully Connected Neural Network\n",
    "\n",
    "# Hidden Layer 1 - Activation Function RELU\n",
    "classifier.add(Dense(units = 512, activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the CNN\n",
    "# Categorical Crossentropy - to classify between multiple classes of images\n",
    "#optimizer = RMSprop(lr=0.0001, decay=1e-6)\n",
    "#optimizer = SGD(lr=0.0001, decay=1e-6)\n",
    "classifier.compile(optimizer = 'adadelta' , loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image Augmentation and Training Section\n",
    "\n",
    "# Image Augmentation to prevent Overfitting (Applying random transformation on images to train set.ie. \n",
    "# scalling, rotating and streching)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=0.3,\n",
    "        width_shift_range=0.3\n",
    "        )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset folder\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the test data set folder\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the accuracy and loss data to plot the graph\n",
    "\n",
    "history = History()\n",
    "checkpoint = ModelCheckpoint(filepath='models_backups/' + str(str(datetime.datetime.now().minute) + \"-\" + str(datetime.datetime.now().second)), monitor='val_loss',verbose=0, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,334,883\n",
      "Trainable params: 1,334,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9000/9000 [==============================] - 1910s - loss: 0.4835 - acc: 0.7581 - val_loss: 0.3454 - val_acc: 0.8400\n",
      "Epoch 2/20\n",
      "9000/9000 [==============================] - 1658s - loss: 0.3434 - acc: 0.8431 - val_loss: 0.3403 - val_acc: 0.8491\n",
      "Epoch 3/20\n",
      "9000/9000 [==============================] - 1625s - loss: 0.2922 - acc: 0.8724 - val_loss: 0.3180 - val_acc: 0.8730\n",
      "Epoch 4/20\n",
      "1317/9000 [===>..........................] - ETA: 1056s - loss: 0.2767 - acc: 0.8804"
     ]
    }
   ],
   "source": [
    "#Fit the clasifier on the CNN data\n",
    "if(os.path.isfile('my_model.h5') == False):\n",
    "    classifier.fit_generator(\n",
    "            training_set,\n",
    "            steps_per_epoch=9000,\n",
    "            epochs=20,\n",
    "            validation_data=test_set,\n",
    "            validation_steps=3000,\n",
    "            callbacks = [history, checkpoint]\n",
    "    )\n",
    "    # Save the generated model to my_model.h5\n",
    "    classifier.save('my_model.h5')\n",
    "else:\n",
    "    classifier = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the labels for the classes according to the folder structre of clases\n",
    "def get_labels_for_clases():\n",
    "    #return ['car', 'cat', 'dog', 'shoe']\n",
    "    return ['car' ,'cat', 'dog']\n",
    "\n",
    "# Run prediction for a single image\n",
    "def predict_for_single_image(image):\n",
    "    #lable the images according the folder structure\n",
    "\n",
    "    lables = get_labels_for_clases()\n",
    "    out = classifier.predict_classes(image)\n",
    "    print(\"Prediction index : \", out)\n",
    "    print(\"Prediction : \", lables[out[0]])\n",
    "    #print(classifier.summary())\n",
    "\n",
    "# Run Prediction for image and give the output as presentatges for each class similarities\n",
    "def predict_probabilities_for_classes(classifier ,image):\n",
    "    labels = get_labels_for_clases()\n",
    "    probabilities = classifier.predict(test_image)\n",
    "    print(probabilities)\n",
    "    # Expand two arrays to relevent class structure\n",
    "    probabilities  = [(format(x * 100, '.2f') + \"%\") for x in probabilities[0]]\n",
    "\n",
    "    print(list(zip(labels, probabilities)))\n",
    "    \n",
    "# Plot the graphs\n",
    "def plot_graphs_on_data(history):\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epocs')\n",
    "    plt.legend(['Train Data', 'Test Data'], loc = 'upper left')\n",
    "    plt.show()\n",
    "\n",
    "    #Plot Loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epocs')\n",
    "    plt.legend(['Train Data', 'Test Data'], loc = 'upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw the Graph for the predicted Results\n",
    "# use this only after training.\n",
    "plot_graphs_on_data(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = img.load_img('custom_test/cat9.jpg', target_size=(64, 64))\n",
    "test_image = img.img_to_array(image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "print(training_set.class_indices)\n",
    "predict_probabilities_for_classes(classifier, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
